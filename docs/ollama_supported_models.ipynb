{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bacb8fa-9eae-4b6c-ac01-000a0e59b7ee",
   "metadata": {},
   "source": [
    "## Summary Table of Ollama Supported Model Architectures\n",
    "\n",
    "| **Model** | **Version** | **Developer** | **Parameters** | **Default Context Window** | **Max Context Window** | **Usage** | **Training Data** |\n",
    "|:----------|:------------|:------------|:-------------|:---------------|:---------------|:--------------|:------------------|\n",
    "| [Llama](https://registry.ollama.com/library/llama2)            | 2        | Meta      | 7B, 13B, 70B  | 4,096 tokens  | 65,536 tokens |General-purpose tasks, convo agents | Diverse dataset, including web text |\n",
    "| [Llama](https://registry.ollama.com/library/llama3.1)          | 3.1      | Meta      | 8B, 70B, 405B | 8,192 tokens  | 128,000 tokens |Improved language tasks, enhanced applications | Expanded dataset for robustness | \n",
    "| [Llama](https://registry.ollama.com/library/llama3.2)          | 3.2      | Meta      | 1B, 3B        | 4,096 tokens  | 131,072 tokens |Specialized tasks, optimized for efficiency | Further refined datasets | \n",
    "| [Gemma](https://registry.ollama.com/library/gemma2)            | 2        | Google    | 2B, 9B, 27B   | 8,000 tokens  | 16,000 tokens |Natural language processing tasks | Proprietary and public datasets | \n",
    "| [Nemotron](https://registry.ollama.com/library/nemotron-mini)  | Mini     | Nvidia    | 4.2B          | 1,024 tokens  | 4,096 tokens |Niche applications in specific domains | Specialized datasets | \n",
    "| [Phi](https://registry.ollama.com/library/phi3)                | 3 Mini   | Microsoft | 3B            | 4,096 tokens  | 8,192 tokens |Lightweight tasks, quick responses | High quality educational content | \n",
    "| [Phi](https://registry.ollama.com/library/phi3)                | 3 Medium | Microsoft | 14B           | 8,192 tokens  | 16,384 tokens |Commercial applications, deeper understanding | Broad range of text sources | \n",
    "| [Phi](https://registry.ollama.com/library/phi3.5)              | 3.5      | Microsoft | 3.8B          | 16,384 tokens | 32,768 tokens |Advanced language models for various tasks | Continuous updates from diverse datasets | \n",
    "| [Mistral](https://registry.ollama.com/library/mistral)         | 0.3      | Mistral   | 7B            | 4,096 tokens  | 131,072 tokens |Inference efficiency in LLM applications | Multilingual datasets and diverse sources | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b08a08-92db-451e-a834-239474e1ca2d",
   "metadata": {},
   "source": [
    "## Summary Table of Ollama Supported Embedding Models\n",
    "\n",
    "| **Model** | **Developer** | **Architecture** | **Dimensions** | **Training Data** | **Use Cases** | **Speed** | **Compatibility** | **Context Window Size** | **Fine-tuning Capabilities** |\n",
    "|:----------|:--------------|:-----------------|:---------------|:------------------|:--------------|:----------|:------------------|:------------------|:--------------|\n",
    "| all-minilm | Microsoft | BERT (transformer-based) | 384 | General text corpus | Semantic search, sentence similarity | High Efficiency   | Weaviate, other databases | 512 tokens | Yes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a3e78-30fd-4f4d-b7ab-fece8c710730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
