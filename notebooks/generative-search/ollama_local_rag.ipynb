{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd18ae9-2fa8-4f66-a51c-f9ea7b7f7124",
   "metadata": {},
   "source": [
    "\n",
    "# Local Retrieval-Augmented Generation (RAG) Pipeline in Python via Ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f66236-8b61-48df-93ef-ea194ba517d0",
   "metadata": {},
   "source": [
    "# Ollama Setup\n",
    "\n",
    "**Ollama** is an open-source Large Language Model (LLM) backend server that streamlines the deployment of LLMs on local environments, utilizing both CPU and GPU resources\n",
    "\n",
    "1. **[Download Ollama](https://ollama.com/download)**\n",
    "\n",
    "2. **Follow the installation instructions**\n",
    "\n",
    "3. **Select models from the [Ollama library](https://ollama.com/library)**\n",
    "\n",
    "For the remaining steps, open a terminal\n",
    "\n",
    "4. **Pull the models**\n",
    "\n",
    "> ```bash\n",
    "> ollama pull llama2      # Language model\n",
    "> ollama pull all-minilm  # Embedding model\n",
    "> ```\n",
    "\n",
    "5. **Install the [Ollama python library](https://github.com/ollama/ollama-python/blob/main/README.md)**:\n",
    "\n",
    "> ```bash\n",
    "> pip install ollama==0.1.8 # Install Ollama Python library (version 0.1.8)\n",
    "> ```\n",
    "\n",
    "> > ```bash\n",
    "> > pip show ollama # Check the version\n",
    "> > ```\n",
    "\n",
    "6. **Verify model**  \n",
    "\n",
    "> ```bash\n",
    "> ollama run llama2\n",
    "> ```\n",
    "\n",
    "7. **Start the Ollama service for Jupyter notebook connection (VS Code TBD)**  \n",
    "\n",
    "> ```bash\n",
    "> ollama serve &\n",
    "> ```\n",
    "\n",
    "\n",
    "#### Key Features of Ollama \n",
    "\n",
    "- **Optimized Performance:** Efficiently leverages both CPU and GPU hardware to maximize the speed and performance of supported LLMs\n",
    "- **Flexible Deployment:** Supports easy setup and deployment on local machines, enabling developers full control over model training and inference\n",
    "- **Scalable Architecture:** Designed to handle varying workloads, making it suitable for both small-scale projects and large enterprise applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cca788-b964-4b2a-a611-6eef0a5ac248",
   "metadata": {},
   "source": [
    "# Chat Query with Llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e0109fd3-cb42-4ea1-bb34-0379fd686945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering, which occurs when sunlight enters Earth's atmosphere. The sunlight encounters tiny molecules of gases in the air, such as nitrogen and oxygen, which scatter the light in all directions.\n",
      "\n",
      "Rayleigh scattering is a process where shorter wavelengths of light (such as blue and violet) are scattered more than longer wavelengths (such as red and orange). This is because the smaller wavelengths have shorter paths in the atmosphere, which allows them to be scattered more easily.\n",
      "\n",
      "As a result of this scattering, the blue light is dispersed throughout the atmosphere, giving the sky its blue appearance. The blue color can appear more intense near the horizon due to the extra scattering that occurs when light passes through more air molecules in the atmosphere.\n",
      "\n",
      "It's worth noting that the color of the sky can vary depending on a number of factors, including the time of day, weather conditions, and atmospheric phenomena such as sunsets or sunrises. However, in general, the blue color of the sky is due to the scattering of sunlight by the atmosphere.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the Ollama library to interact with the language models\n",
    "import ollama\n",
    "\n",
    "# Send a chat request to the 'llama2' model with a user message\n",
    "response = ollama.chat(model='llama2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',  # Message content that the user sends to the model\n",
    "  },\n",
    "])\n",
    "\n",
    "# Print the response from the model, displaying the answer to the user's question\n",
    "print(response['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089aae18-e7ec-421d-9dbf-acabad108b46",
   "metadata": {},
   "source": [
    "# Generate Vector Embeddings\n",
    "\n",
    "Ollama supports embedding models, making it possible to build RAG applications that combine text prompts with existing documents or other data.\n",
    "\n",
    "**What are embedding models?** \n",
    "Embedding models are models that are trained specifically to generate vector embeddings: long arrays of numbers that represent semantic meaning for a given sequence of text:\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://ollama.com/public/blog/what-are-embeddings.svg\" alt=\"vector_embeddings_ollama\" width=\"500\" />\n",
    "  <figcaption></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "90599b7c-7979-48a4-8416-dbc66f39b591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Embedding length: 384'\n",
      "{'embedding': [0.0479680672287941,\n",
      "               0.11637094616889954,\n",
      "               -0.24570561945438385,\n",
      "               -0.04406300559639931,\n",
      "               -0.24932530522346497,\n",
      "               0.12218563258647919,\n",
      "               -0.48447176814079285,\n",
      "               -0.1940533071756363,\n",
      "               0.27372273802757263,\n",
      "               0.1956769824028015]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Generate vector embeddings for the given text prompt\n",
    "resp = ollama.embeddings(model=\"all-minilm\", \n",
    "                      prompt=\"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\");\n",
    "\n",
    "# The resulting vector embedding arrays can then be stored in a database, \n",
    "# which will compare them as a way to search for data that is similar in meaning\n",
    "\n",
    "# Limit the print output to the first 10 values\n",
    "pprint(f\"Embedding length: {len(resp['embedding'])}\")\n",
    "pprint({'embedding': resp['embedding'][:10]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240a206-8282-4518-960a-09a9822a4418",
   "metadata": {},
   "source": [
    "# Weaviate Setup\n",
    "\n",
    "**Weaviate** is an open-source, AI-native vector database designed to store and manage large-scale data. It provides advanced capabilities for AI-driven applications, making it easier to handle data ingestion, querying, and search operations.\n",
    "\n",
    "1. **Install [Python Weaviate library](https://weaviate.io/developers/weaviate/client-libraries/python)**:\n",
    "\n",
    "> ```bash\n",
    "> pip install -U weaviate-client  # Install Weaviate client library (version 4.5.5)\n",
    "> ```\n",
    "\n",
    "> > ```bash\n",
    "> > pip show weaviate-client # Check the version\n",
    "> > ```\n",
    "\n",
    "#### Key Features of the Weaviate Client Library \n",
    "\n",
    "- **Data Ingestion:** Easily add and manage data within your Weaviate instance \n",
    "- **Querying:** Execute complex queries to retrieve relevant information \n",
    "- **Search Operations:** Perform semantic and vector-based searches for accurate data retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b9ec58ce-f434-4ac3-91b0-b8ba8f1eb70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":52101},\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"address\":\"192.168.0.249:52102\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"address\":\"192.168.0.249:52101\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"action\":\"raft\",\"index\":26,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.0.249:58097}]]\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":31,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":31,\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-10-24T17:27:41-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [192.168.0.249:52101]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"192.168.0.249:52101\"],\"time\":\"2024-10-24T17:27:43-04:00\",\"voter\":true}\n",
      "{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"Embedded_at_8079\",\"Address\":\"192.168.0.249:52101\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"bootstrap only works on new clusters\",\"level\":\"error\",\"msg\":\"could not bootstrapping cluster\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"192.168.0.249:52101\"],\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":13,\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":13,\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"index\":\"Docs\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client connected successfully\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"address\":\"192.168.0.249:52101\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-10-24T17:27:43-04:00\"}\n",
      "{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:4b652bfb-ddcb-471d-8182-2707242e567f Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[]}\",\"time\":\"2024-10-24T17:27:44-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-10-24T17:27:44-04:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-10-24T17:27:44-04:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard docs_r2kyuy3QD2rD in 10.957125ms\",\"time\":\"2024-10-24T17:27:44-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-10-24T17:27:44-04:00\",\"took\":634750}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the Weaviate client library to interact with the Weaviate database\n",
    "import weaviate\n",
    "\n",
    "# Check if the client object already exists to prevent multiple connections\n",
    "if 'client' not in globals():\n",
    "    # Connect to an embedded Weaviate instance\n",
    "    # Python client interacts with the local server at http://127.0.0.1:8079\n",
    "    # using HTTP for queries and gRPC (Google Remote Procedure Call) for faster data communication\n",
    "    # Start process ID path: /Users/briankaewell/.cache/weaviate-embedded/*\n",
    "    client = weaviate.connect_to_embedded() # For quick and basic evaluations\n",
    "    print(\"Client connected successfully\")\n",
    "    \n",
    "else:\n",
    "    print(\"Client is already connected\")\n",
    "\n",
    "# Check if the Weaviate instance is ready and print the connection status\n",
    "print(client.is_ready())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c8c00-d18a-4f5d-abe8-e9d67b34d8df",
   "metadata": {},
   "source": [
    "# Implement a Local RAG Pipeline\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://weaviate.io/assets/images/rag-ollama-diagram-c71ba5c4e60629e70a2cf334a7716860.png\" alt=\"rag_ollama\" width=\"700\" />\n",
    "  <figcaption>Local Retrieval Augmented Generation (RAG) system with language models via Ollama</figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c25995-21bf-4bbe-b1a7-53965dcbd0e2",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a223777a-fd08-4f8e-a759-4f369cd56c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List contains individual pieces of information (documents) related to llamas, \n",
    "# which may be used for processing or data storage tasks\n",
    "documents = [\n",
    "  \"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\",\n",
    "  \"Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands\",\n",
    "  \"Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall\",\n",
    "  \"Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight\",\n",
    "  \"Llamas are vegetarians and have very efficient digestive systems\",\n",
    "  \"Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old\",\n",
    "]\n",
    "#print(documents)\n",
    "\n",
    "\n",
    "# This code retrieves a json file from a remote URL using the 'requests' library, \n",
    "# checks if the request was successful, and then loads and prints the data in JSON format.\n",
    "#import requests\n",
    "#import json\n",
    "#url = 'https://raw.githubusercontent.com/bkaewell/rag-workflow/refs/heads/main/notebooks/generative-search/data/2024-10-23-llamas-json-example.json'\n",
    "#response = requests.get(url)\n",
    "#\n",
    "# Check if the request was successful\n",
    "#if response.status_code == 200:\n",
    "#    print(response.text)\n",
    "#else:\n",
    "#    print(f\"Error: {response.status_code}\")\n",
    "#\n",
    "#data = json.loads(resp.text)  # Load data\n",
    "#print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794419b-173a-4312-9acb-66ec05e62584",
   "metadata": {},
   "source": [
    "# Create Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a364e598-9220-41fb-9677-1b806334bffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"warning\",\"msg\":\"prop len tracker file /Users/briankaewell/.local/share/weaviate/docs/Lr9jb2BShrtX/proplengths does not exist, creating new tracker\",\"time\":\"2024-10-24T17:28:07-04:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-10-24T17:28:07-04:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard docs_Lr9jb2BShrtX in 7.910709ms\",\"time\":\"2024-10-24T17:28:07-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-10-24T17:28:07-04:00\",\"took\":84208}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import specific classes from Weaviate to work with data schema and configs for vector database\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.classes.config import Property, DataType\n",
    "\n",
    "# Define the name of the structure (collection)\n",
    "collection_name = \"docs\"\n",
    "\n",
    "# Check if the collection already exists\n",
    "if client.collections.exists(collection_name):\n",
    "    client.collections.delete(collection_name)\n",
    "\n",
    "# Create a new collection with the specified name and define its structure properties\n",
    "collection = client.collections.create(\n",
    "    collection_name,\n",
    "    properties=[\n",
    "        Property(name=\"text\", \n",
    "                 data_type=DataType.TEXT), # Name and data type of a single property for simple list of strings\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f946e4-1439-4d2a-b611-d7665f3a3584",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d5e53edb-df8f-4384-a863-0dbe92892faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Store each document in a vector embedding database\n",
    "with collection.batch.dynamic() as batch:\n",
    "  for i, d in enumerate(documents):\n",
    "    # For each document, generate its vector embeddings\n",
    "    response = ollama.embeddings(model=\"all-minilm\", \n",
    "                                 prompt=d)\n",
    "    embedding = response[\"embedding\"]\n",
    "    # Print text and its embedding\n",
    "    # display({f'Document {i}': d, \"Embedding\": embedding}) \n",
    "    \n",
    "    # Store data object with combined text and embedding in the vector embedding database\n",
    "    batch.add_object(\n",
    "        properties = {\"text\" : d},\n",
    "        vector = embedding,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fa7071ec-a894-4021-a120-7aae19be8bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('03a34f8b-f227-4183-9b26-b6e27942e5b0'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'text': 'Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands'}, references=None, vector={'default': [0.17213347554206848, 0.16122983396053314, -0.1948625147342682, 0.317971795797348, -0.19478818774223328, -0.2074703574180603, -0.6278446316719055, -0.26288244128227234, -0.052119795233011246, 0.6996364593505859, 0.44047579169273376, -0.2558085322380066, 0.05621032789349556, 0.18558967113494873, -0.01409709919244051, 0.23181354999542236, -0.05545922368764877, -0.264326274394989, 0.20167632400989532, 0.4523124694824219, 0.19254468381404877, -0.10235374420881271, -0.02420978620648384, 0.17560499906539917, 0.08126483857631683, 0.10912062972784042, -0.18565529584884644, -0.04607929289340973, 0.15311601758003235, 0.1156761646270752, -0.38195839524269104, -0.023279564455151558, 0.5545060634613037, 0.046700287610292435, -0.3084549307823181, 0.009847305715084076, 0.2825922667980194, 0.259365439414978, -0.09551888704299927, 0.24693018198013306, 0.23050737380981445, -0.13034364581108093, 0.46054622530937195, -0.425439715385437, -0.21140848100185394, -0.1330603063106537, 0.030701953917741776, 0.1780218929052353, 0.013578837737441063, 0.2036585658788681, 0.2779616415500641, -0.08195498585700989, -0.1492612510919571, -0.3098003566265106, -0.01776091754436493, -0.48093998432159424, -0.009689117781817913, -0.19254398345947266, -0.05004284903407097, 0.3694937527179718, 0.04273020476102829, 0.17203965783119202, 0.024337299168109894, -0.17395997047424316, -0.051440656185150146, -0.12768402695655823, -0.1588560789823532, 0.15943238139152527, 0.11401894688606262, -0.19317609071731567, 0.29973047971725464, -0.10722214728593826, 0.14832648634910583, 0.29649215936660767, -0.7441163063049316, 0.06881341338157654, 0.389909565448761, -0.00267076026648283, -0.12085237354040146, -0.13059425354003906, -0.14350375533103943, 0.15219642221927643, -0.14031407237052917, -0.06752943992614746, -0.14902940392494202, 0.41191112995147705, -0.3142343759536743, 0.06725189834833145, -0.12637922167778015, -0.28936049342155457, 0.2496030330657959, -0.08140275627374649, -0.12553875148296356, 0.0848829448223114, 0.17572878301143646, -0.2562676668167114, -0.030197301879525185, -0.042555876076221466, 0.04073759913444519, -0.0687340497970581, 0.14386659860610962, -0.47563281655311584, -0.07564868032932281, -0.0654955506324768, -0.1150301918387413, -0.1311950385570526, -0.42719438672065735, 0.053856391459703445, -0.07772155106067657, 0.1916721612215042, -0.2609739303588867, 0.09003384411334991, -0.20177191495895386, 0.7118816375732422, -0.16966462135314941, -0.033247675746679306, 0.07274860888719559, -0.08655379712581635, -0.004385771229863167, -0.16257469356060028, -0.13747504353523254, 0.09814494103193283, 0.25544118881225586, -0.1446124017238617, 0.4252598285675049, -0.19188463687896729, 0.32813066244125366, -7.522919930184844e-33, 0.2335253357887268, -0.5016195178031921, -0.22710606455802917, 0.25435614585876465, 0.17646054923534393, -0.12560801208019257, 0.1336844265460968, 0.28512632846832275, -0.0009085685014724731, 0.040969572961330414, -0.20963206887245178, -0.030910765752196312, 0.11418535560369492, -0.16374531388282776, 0.07818260043859482, 0.126443549990654, 0.041880786418914795, -0.7108064293861389, 0.5032752752304077, -0.30332380533218384, -0.31028783321380615, 0.13427069783210754, 0.3069338798522949, -0.00889599695801735, 0.06752631813287735, 0.12499377131462097, 0.020456913858652115, -0.5599921941757202, -0.24446430802345276, 0.13214421272277832, 0.16316011548042297, -0.39194220304489136, -0.22527068853378296, -0.03634553402662277, -0.14186067879199982, 0.2557942569255829, 0.08725374191999435, -0.11975986510515213, -0.2197936773300171, 0.16060104966163635, 0.5003655552864075, -0.18276585638523102, 0.2030579149723053, -0.16314172744750977, -0.034722186625003815, 0.029128119349479675, -0.024122897535562515, 0.5168289542198181, -0.1364104449748993, 0.22361576557159424, -0.041874952614307404, 0.252743124961853, -0.13653776049613953, -0.15323083102703094, -0.5292746424674988, -0.22031563520431519, 0.10452206432819366, -0.025669027119874954, -0.18787917494773865, 0.1300230622291565, 0.29780808091163635, -0.08248523622751236, 0.34050238132476807, -0.022348105907440186, 0.1833498477935791, -0.24075621366500854, 0.04715835675597191, 0.2756851017475128, 0.29458820819854736, -0.2682357132434845, 0.3480231761932373, 0.028478335589170456, -0.256461501121521, -0.3377034366130829, 0.20348824560642242, -0.09102656692266464, 0.4985246956348419, 0.18480759859085083, 0.2956463694572449, 0.034806109964847565, 0.28377681970596313, 0.3941044211387634, -0.22758522629737854, 0.35571321845054626, -0.2517473101615906, 0.43970057368278503, 0.4345371425151825, 0.33492234349250793, 0.07456810772418976, -0.057270597666502, 0.06808411329984665, 0.05173000693321228, 0.13490597903728485, -0.519385814666748, 0.19580554962158203, -5.59102949475497e-34, -0.30771803855895996, 0.02953008934855461, 0.19656318426132202, 0.2998104989528656, -0.05925583094358444, -0.44179636240005493, -0.3584689497947693, 0.369350403547287, -0.3353976607322693, -0.1948087364435196, -0.1014753207564354, -0.11235965043306351, 0.32661202549934387, -0.2658509910106659, 0.35522350668907166, -0.11168833076953888, -0.42604732513427734, -0.40171223878860474, 0.1569153070449829, -0.3806735873222351, -0.3120025396347046, -0.092039555311203, 0.013109296560287476, -0.2052285373210907, -0.05423229932785034, -0.11312144249677658, 0.012350309640169144, -0.09597211331129074, -0.024067861959338188, -0.04534652829170227, -0.17886923253536224, -0.13117057085037231, 0.05846842750906944, -0.09031886607408524, -0.1400444507598877, -0.0682068020105362, -0.19707588851451874, 0.27018582820892334, 0.13765749335289001, 0.12310106307268143, 0.1448502242565155, 0.45053553581237793, -0.13318988680839539, 0.2048010379076004, -0.246637761592865, 0.12878164649009705, 0.011692486703395844, 0.04410123825073242, 0.4248534142971039, 0.009128902107477188, 0.707758903503418, -0.025631863623857498, -6.946548819541931e-05, -0.45885246992111206, 0.15659454464912415, -0.3218851685523987, 0.1296953409910202, 0.09251062572002411, -0.3522469401359558, -0.1242152601480484, -0.41589856147766113, 0.011655192822217941, -0.3400242328643799, -0.047044891864061356, 0.011172566562891006, 0.1155184730887413, -0.14211377501487732, 0.030435048043727875, -0.24336941540241241, -0.18286021053791046, 0.4556681513786316, -0.09126149117946625, -0.1961331069469452, -0.17742575705051422, 0.011656804010272026, -0.16457726061344147, -0.163554847240448, 0.006113745272159576, 0.6201328039169312, -0.0583898164331913, -0.21264909207820892, -0.09756075590848923, 0.2901456356048584, 0.2586720585823059, -0.05265627056360245, 0.03873985633254051, 0.18101780116558075, 0.24217411875724792, 0.08281306177377701, 0.37385308742523193, -0.06572398543357849, -0.07311677932739258, -0.012169543653726578, 0.047969479113817215, 0.0657939538359642, -9.836568182208794e-08, -0.15211883187294006, 0.055087752640247345, -0.05371062085032463, 0.29788416624069214, 0.14782989025115967, 0.35948413610458374, 0.06447834521532059, 0.25790849328041077, 0.2961013913154602, 0.14465847611427307, -0.006690884009003639, 0.28122442960739136, 0.0843411237001419, 0.06377280503511429, 0.03495880588889122, -0.10306026041507721, 0.36952656507492065, 0.03512896969914436, -0.04425625503063202, 0.13174016773700714, -0.2977522015571594, 0.1455894112586975, -0.1935909539461136, -0.4215250313282013, -0.17057877779006958, -0.25867438316345215, -0.534705400466919, 0.034436535090208054, 0.31145069003105164, -0.011191263794898987, -0.3081652522087097, -0.09267492592334747, -0.3106245994567871, -0.35463035106658936, 0.14738516509532928, -0.12018720805644989, -0.2311333417892456, -0.23274604976177216, 0.10368728637695312, -0.3448200821876526, 0.23334234952926636, -0.02398771420121193, -0.09321030229330063, 0.14228154718875885, -0.12727689743041992, -0.15649166703224182, -0.2000628262758255, 0.16323471069335938, -0.2633531987667084, -0.15070411562919617, -0.19651645421981812, 0.14267078042030334, 0.2896975874900818, -0.15396109223365784, -0.09667420387268066, -0.45335453748703003, 0.029788605868816376, -0.40209364891052246, 0.31508100032806396, 0.4381369948387146, -0.059245526790618896, 0.15814165771007538, -0.039216719567775726, 0.2481113076210022]}, collection='Docs')])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Query the collection to fetch objects, retrieving only the closet \n",
    "# result (limit=1), and include their vector representations in the response\n",
    "collection.query.fetch_objects(limit=1, include_vector=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f37eebd-b108-4936-b3b3-cb6b14ee67d5",
   "metadata": {},
   "source": [
    "# Retrieve Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "581a5bcd-87fb-49fc-a99a-9c97b4051fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the prompt for which you want to find the most relevant document\n",
    "prompt = \"What animals are llamas related to?\"\n",
    "\n",
    "# Generate an embedding for the prompt using the specified model 'all-minilm'\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=\"all-minilm\"\n",
    ")\n",
    "\n",
    "# Query the collection to retrieve the MOST relevant document (limit=1) based on the prompt's embedding\n",
    "results = collection.query.near_vector(near_vector=response[\"embedding\"],\n",
    "                             limit=1)\n",
    "\n",
    "# Extract and display the text of the most relevant document\n",
    "data = results.objects[0].properties['text']\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df904749-538b-49fb-8f1e-d109e3241947",
   "metadata": {},
   "source": [
    "# Augment the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d995b152-aa92-4d06-aff5-bd9f1b4524ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a prompt template that combines the retrieved context (data) \n",
    "# with the original prompt to generate a comprehensive response\n",
    "prompt_template = f\"Using this data: {data}. Respond to this prompt: {prompt}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c9275-47e5-4d79-bbc3-eb38f518fda3",
   "metadata": {},
   "source": [
    "# Generate a Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cc15b5d4-a264-4034-89cd-48f12d8b15a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Llamas are related to several other animals within the camelid family, including:\n",
      "\n",
      "1. Vicuñas: Vicuñas are small, wild relatives of llamas and alpacas. They are native to South America and are known for their soft, velvety fur.\n",
      "2. Camels: As you mentioned, llamas are closely related to camels. Both llamas and camels belong to the Camelidae family and share many similarities in terms of their physical characteristics and behavior.\n",
      "3. Alpacas: Alpacas are also members of the camelid family and are closely related to llamas. They are native to South America and are known for their soft, fleecy fur.\n",
      "\n",
      "So, in summary, llamas are related to vicuñas, camels, and alpacas within the camelid family.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Generate a response from the augmented prompt template\n",
    "output = ollama.generate(\n",
    "  model=\"llama2\",\n",
    "  prompt=prompt_template,\n",
    ")\n",
    "\n",
    "# Print the generated response to the prompt\n",
    "print(output['response'])\n",
    "\n",
    "# Llama2 will answer the prompt \"What animals are llamas related to?\" using the data: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8f524490-5b23-4364-9157-e47e12a3f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the embedded Weaviate instance\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb227ced-b79d-4e0e-96a4-611f32976979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
