{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd18ae9-2fa8-4f66-a51c-f9ea7b7f7124",
   "metadata": {},
   "source": [
    "\n",
    "# Local Retrieval Augmented Generator (RAG) Pipeline in Python via Ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f66236-8b61-48df-93ef-ea194ba517d0",
   "metadata": {},
   "source": [
    "## Quick Start Guide for Ollama Setup\n",
    "\n",
    "**Ollama** is an open-source Large Language Model (LLM) backend server that streamlines the deployment of LLMs on local environments, utilizing both CPU and GPU resources\n",
    "\n",
    "1. **Download and Install Ollama**  \n",
    "   [Download Ollama]((https://ollama.com/download)) and follow the installation instructions\n",
    "\n",
    "2. **Select Models**  \n",
    "   Browse and choose supported models from the [Ollama library](https://ollama.com/library)\n",
    "\n",
    "3. **Pull the Models**  \n",
    "   Open a terminal and pull the following models:\n",
    "\n",
    "> ```bash\n",
    "> ollama pull llama2      # Language model\n",
    "> ollama pull all-minilm  # Embedding model\n",
    "> ```\n",
    "\n",
    "4. **Install the [Ollama Python library](https://github.com/ollama/ollama-python/blob/main/README.md)**:\n",
    "\n",
    "> ```bash\n",
    "> pip install ollama==0.1.8 # Install Ollama Python library (version 0.1.8)\n",
    "> ```\n",
    "\n",
    "5. **Verify Model Execution**  \n",
    "   Run the model in the terminal to verify it works\n",
    "\n",
    "> ```bash\n",
    "> ollama run llama2\n",
    "> ```\n",
    "\n",
    "6. **Start the Ollama Service for Jupyter Notebook Connection**  \n",
    "   Run the following command in the terminal to start the Ollama service in the background:\n",
    "\n",
    "> ```bash\n",
    "> ollama serve &\n",
    "> ```\n",
    "\n",
    "\n",
    "#### Key Features of Ollama \n",
    "\n",
    "- **Optimized Performance:** Efficiently leverages both CPU and GPU hardware to maximize the speed and performance of supported LLMs\n",
    "- **Flexible Deployment:** Supports easy setup and deployment on local machines, enabling developers full control over model training and inference\n",
    "- **Scalable Architecture:** Designed to handle varying workloads, making it suitable for both small-scale projects and large enterprise applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cca788-b964-4b2a-a611-6eef0a5ac248",
   "metadata": {},
   "source": [
    "# Chat Query with Llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e0109fd3-cb42-4ea1-bb34-0379fd686945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen and oxygen. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is known as Rayleigh scattering.\n",
      "\n",
      "As a result of this scattering, the blue light is dispersed throughout the atmosphere, giving the sky its blue color. The red light, on the other hand, is able to travel longer distances without being scattered, which is why the sun appears yellow when it is overhead.\n",
      "\n",
      "It's worth noting that the color of the sky can appear different under different conditions. For example, during sunrise and sunset, the sky can take on hues of red, orange, and pink due to the angle of the sunlight and the scattering of light by particles in the atmosphere.\n",
      "\n",
      "Additionally, the color of the sky can also be affected by pollution, dust, and other particles in the atmosphere, which can scatter light in different ways and alter the appearance of the sky.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the Ollama library to interact with the language models\n",
    "import ollama\n",
    "\n",
    "# Send a chat request to the 'llama2' model with a user message\n",
    "response = ollama.chat(model='llama2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',  # Message content that the user sends to the model\n",
    "  },\n",
    "])\n",
    "\n",
    "# Print the response from the model, displaying the answer to the user's question\n",
    "print(response['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089aae18-e7ec-421d-9dbf-acabad108b46",
   "metadata": {},
   "source": [
    "# Generate Vector Embeddings\n",
    "\n",
    "Ollama supports embedding models, making it possible to build RAG applications that combine text prompts with existing documents or other data.\n",
    "\n",
    "**What are embedding models?** \n",
    "Embedding models are models that are trained specifically to generate vector embeddings: long arrays of numbers that represent semantic meaning for a given sequence of text:\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://ollama.com/public/blog/what-are-embeddings.svg\" alt=\"vector_embeddings_ollama\" width=\"500\" />\n",
    "  <figcaption></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "90599b7c-7979-48a4-8416-dbc66f39b591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Embedding length: 384'\n",
      "{'embedding': [-0.029126940295100212,\n",
      "               0.2337689846754074,\n",
      "               -0.4055681526660919,\n",
      "               0.29721516370773315,\n",
      "               -0.4429345726966858,\n",
      "               0.14598685503005981,\n",
      "               -0.5178152918815613,\n",
      "               -0.5079879760742188,\n",
      "               0.16581414639949799,\n",
      "               0.4793556332588196]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Generate vector embeddings for the given text prompt\n",
    "ollama.embeddings(model=\"all-minilm\", \n",
    "                  prompt=\"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\");\n",
    "\n",
    "# The resulting vector embedding arrays can then be stored in a database, \n",
    "# which will compare them as a way to search for data that is similar in meaning\n",
    "\n",
    "# Limit the print output to the first 10 values\n",
    "pprint(f\"Embedding length: {len(response['embedding'])}\")\n",
    "pprint({'embedding': response['embedding'][:10]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240a206-8282-4518-960a-09a9822a4418",
   "metadata": {},
   "source": [
    "## Quick Start Guide for Weaviate Setup\n",
    "\n",
    "**Weaviate** is an open-source, AI-native vector database designed to store and manage large-scale data. It provides advanced capabilities for AI-driven applications, making it easier to handle data ingestion, querying, and search operations.\n",
    "\n",
    "1. **Install [Python Weaviate library](https://weaviate.io/developers/weaviate/client-libraries/python)**:\n",
    "\n",
    "> ```bash\n",
    "> pip install -U weaviate-client  # Install Weaviate client library (version 4.5.5)\n",
    "> ```\n",
    "\n",
    "#### Key Features of the Weaviate Client Library \n",
    "\n",
    "- **Data Ingestion:** Easily add and manage data within your Weaviate instance \n",
    "- **Querying:** Execute complex queries to retrieve relevant information \n",
    "- **Search Operations:** Perform semantic and vector-based searches for accurate data retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b9ec58ce-f434-4ac3-91b0-b8ba8f1eb70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":59033},\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"address\":\"192.168.0.249:59034\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"address\":\"192.168.0.249:59033\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"action\":\"raft\",\"index\":26,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.0.249:58097}]]\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":24,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":28,\"time\":\"2024-10-16T15:15:41-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [192.168.0.249:59033]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"192.168.0.249:59033\"],\"time\":\"2024-10-16T15:15:43-04:00\",\"voter\":true}\n",
      "{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"Embedded_at_8079\",\"Address\":\"192.168.0.249:59033\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"bootstrap only works on new clusters\",\"level\":\"error\",\"msg\":\"could not bootstrapping cluster\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"192.168.0.249:59033\"],\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":12,\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":12,\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"index\":\"Docs\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"address\":\"192.168.0.249:59033\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n",
      "{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-10-16T15:15:43-04:00\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client connected successfully\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:bbbbab42-1c22-414c-850f-9540965ecd98 Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[]}\",\"time\":\"2024-10-16T15:15:44-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-10-16T15:15:44-04:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-10-16T15:15:45-04:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard docs_4bBWqRTgOSo2 in 17.336917ms\",\"time\":\"2024-10-16T15:15:45-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-10-16T15:15:45-04:00\",\"took\":383167}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the Weaviate client library to interact with the Weaviate database\n",
    "import weaviate\n",
    "\n",
    "# Check if the client object already exists to prevent multiple connections\n",
    "if 'client' not in globals():\n",
    "    # Connect to an embedded Weaviate instance\n",
    "    # Python client interacts with the local server at http://127.0.0.1:8079\n",
    "    # using HTTP for queries and gRPC (Google Remote Procedure Call) for faster data communication\n",
    "    # Start process ID path: /Users/briankaewell/.cache/weaviate-embedded/*\n",
    "    client = weaviate.connect_to_embedded()\n",
    "    print(\"Client connected successfully\")\n",
    "    \n",
    "else:\n",
    "    print(\"Client is already connected\")\n",
    "\n",
    "# Check if the Weaviate instance is ready and print the connection status\n",
    "print(client.is_ready())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c29207-3236-4e56-aba0-493510fc62ef",
   "metadata": {},
   "source": [
    "# Verify Open Network Port Sockets in LISTEN mode on the System\n",
    "\n",
    "**The grep LISTEN filter displays only those network ports that are actively listening for incoming connections**\n",
    "\n",
    "> ``` \n",
    "> sudo lsof -i -P -n | grep LISTEN \n",
    "> \n",
    "> ollama    27370   IPv4 0xdfbc846e3834546d      0t0    TCP 127.0.0.1:11434 (LISTEN) \n",
    ">\n",
    "> weaviate- 35147   IPv6 0x53a13eedd360c342      0t0    TCP *:60186 (LISTEN) \n",
    "> weaviate- 35147   IPv6 0x91f60d5cf4124a61      0t0    TCP *:6060 (LISTEN) \n",
    "> weaviate- 35147   IPv4 0x2acb043cb27d74a0      0t0    TCP 192.168.0.249:60188 (LISTEN) \n",
    "> weaviate- 35147   IPv6 0x41d21a8cc4514707      0t0    TCP *:60187 (LISTEN) \n",
    "> weaviate- 35147   IPv4 0xf61841243b061880      0t0    TCP 192.168.0.249:60187 (LISTEN) \n",
    "> weaviate- 35147   IPv6 0x515655760ad88e38      0t0    TCP *:50050 (LISTEN) \n",
    "> weaviate- 35147   IPv4 0x379147eef7c0a3e5      0t0    TCP 127.0.0.1:8079 (LISTEN)\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c8c00-d18a-4f5d-abe8-e9d67b34d8df",
   "metadata": {},
   "source": [
    "# Implement a Local RAG Pipeline\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://weaviate.io/assets/images/rag-ollama-diagram-c71ba5c4e60629e70a2cf334a7716860.png\" alt=\"rag_ollama\" width=\"700\" />\n",
    "  <figcaption>Local Retrieval Augmented Generation (RAG) system with language models via Ollama</figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c25995-21bf-4bbe-b1a7-53965dcbd0e2",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a223777a-fd08-4f8e-a759-4f369cd56c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List contains individual pieces of information (documents) related to llamas, \n",
    "# which may be used for processing or data storage tasks\n",
    "documents = [\n",
    "  \"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\",\n",
    "  \"Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands\",\n",
    "  \"Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall\",\n",
    "  \"Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight\",\n",
    "  \"Llamas are vegetarians and have very efficient digestive systems\",\n",
    "  \"Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794419b-173a-4312-9acb-66ec05e62584",
   "metadata": {},
   "source": [
    "# Create Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a364e598-9220-41fb-9677-1b806334bffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"warning\",\"msg\":\"prop len tracker file /Users/briankaewell/.local/share/weaviate/docs/r2kyuy3QD2rD/proplengths does not exist, creating new tracker\",\"time\":\"2024-10-16T15:16:27-04:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-10-16T15:16:27-04:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard docs_r2kyuy3QD2rD in 10.515708ms\",\"time\":\"2024-10-16T15:16:27-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-10-16T15:16:27-04:00\",\"took\":85625}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import specific classes from Weaviate to work with data schema and configs for vector database\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.classes.config import Property, DataType\n",
    "\n",
    "# Define the name of the structure (collection)\n",
    "collection_name = \"docs\"\n",
    "\n",
    "# Check if the collection already exists\n",
    "if client.collections.exists(collection_name):\n",
    "    client.collections.delete(collection_name)\n",
    "\n",
    "# Create a new collection with the specified name and define its structure properties\n",
    "collection = client.collections.create(\n",
    "    collection_name,\n",
    "    properties=[\n",
    "        Property(name=\"text\", \n",
    "                 data_type=DataType.TEXT), # Name and data type of a single property for simple list of strings\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f946e4-1439-4d2a-b611-d7665f3a3584",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d5e53edb-df8f-4384-a863-0dbe92892faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Store each document in a vector embedding database\n",
    "with collection.batch.dynamic() as batch:\n",
    "  for i, d in enumerate(documents):\n",
    "    # For each document, generate its vector embeddings\n",
    "    response = ollama.embeddings(model=\"all-minilm\", \n",
    "                                 prompt=d)\n",
    "    embedding = response[\"embedding\"]\n",
    "    # Print text and its embedding\n",
    "    # display({f'Document {i}': d, \"Embedding\": embedding}) \n",
    "    \n",
    "    # Store data object with combined text and embedding in the vector embedding database\n",
    "    batch.add_object(\n",
    "        properties = {\"text\" : d},\n",
    "        vector = embedding,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fa7071ec-a894-4021-a120-7aae19be8bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('0c031f19-3d46-4368-a4d0-a5b6b13f7434'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'text': 'Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall'}, references=None, vector={'default': [0.008789915591478348, 0.10739472508430481, -0.1668676733970642, -0.09627924859523773, -0.06049688160419464, 0.03991207480430603, -0.6782335042953491, 0.08015238493680954, 0.00865126121789217, 0.45973312854766846, 0.1115339919924736, -0.24998602271080017, 0.14255616068840027, -0.10874465107917786, 0.004507740028202534, 0.33585697412490845, 0.1485360860824585, 0.05385897308588028, -0.2558134198188782, 0.32242637872695923, 0.4933672249317169, 0.1559758484363556, 0.06016724556684494, 0.14677272737026215, 0.03190439194440842, -0.05756274610757828, -0.2280501425266266, 0.18351460993289948, 0.0811276063323021, -0.013948671519756317, -0.3116587698459625, 0.3522184491157532, 0.37846076488494873, -0.0686798170208931, -0.08261586725711823, -0.2993246018886566, 0.3076937794685364, 0.291942298412323, 0.17990311980247498, 0.3294980823993683, 0.2950400710105896, 0.21177145838737488, 0.15655651688575745, -0.3203103244304657, 0.014374599792063236, -0.41439396142959595, -0.15508237481117249, 0.21501697599887848, -0.4756675660610199, -0.18895824253559113, 0.053952787071466446, -0.00044119637459516525, -0.2480897456407547, -0.16970841586589813, 0.10725335031747818, -0.294854074716568, -0.1430269330739975, -0.27232474088668823, 0.03519543632864952, 0.15004758536815643, 0.15783905982971191, 0.13096709549427032, 0.02062053233385086, -0.3477857708930969, 0.13221625983715057, -0.13856542110443115, -0.5281335711479187, 0.15332023799419403, -0.1698104739189148, -0.14470559358596802, -0.06341502070426941, 0.07299890369176865, -0.012430744245648384, 0.5076109170913696, -0.4438665211200714, -0.17142358422279358, 0.3590477705001831, 0.16673099994659424, 0.21823005378246307, 0.2514622211456299, -0.28222137689590454, -0.01854994148015976, -0.47114187479019165, 0.01710832491517067, -0.38486748933792114, 0.037363000214099884, -0.07560577243566513, 0.06415024399757385, -0.009857704862952232, -0.013353360816836357, 0.18098287284374237, -0.24716690182685852, -0.34650471806526184, 0.027329914271831512, -0.0772261843085289, -0.21649938821792603, -0.1029132828116417, -0.6494715213775635, -0.38105952739715576, -0.2551537752151489, 0.37580540776252747, -0.3219912052154541, 0.02764713019132614, -0.013397393748164177, -0.09235095977783203, 0.1463618278503418, -0.08524304628372192, 0.20460331439971924, 0.2689920961856842, 0.009553547017276287, -0.09108874946832657, 0.06797664612531662, -0.11832498013973236, 0.6808395385742188, -0.03203529492020607, -0.07628674060106277, 0.10735958814620972, -0.18754976987838745, -0.12353061139583588, -0.24971067905426025, 0.09049680829048157, 0.17943213880062103, 0.342814564704895, -0.04352617263793945, 0.28572285175323486, -0.24228370189666748, 0.13260048627853394, 1.2420963913719398e-32, 0.06120254844427109, -0.06824477016925812, 0.18692001700401306, 0.05452203378081322, 0.4799926280975342, -0.025826212018728256, -0.16394931077957153, 0.04943849518895149, -0.207057386636734, 0.32084351778030396, -0.5849300026893616, 0.3284478783607483, 0.22682322561740875, -0.12152251601219177, 0.17821571230888367, 0.03880088031291962, 0.23729419708251953, 0.031203415244817734, -0.1945655643939972, -0.2988432049751282, -0.07747603207826614, -0.013762467540800571, 0.23801365494728088, -0.02223964035511017, 0.1517573595046997, 0.054478470236063004, 0.35172194242477417, -0.389310359954834, -0.43403810262680054, 0.0038217343389987946, -0.004617205820977688, -0.1071467250585556, 0.05654585734009743, 0.05203070491552353, 0.040347546339035034, -0.1534738689661026, 0.03796270117163658, 0.25369781255722046, -0.22039808332920074, -0.10694903135299683, 0.6619864702224731, -0.11820338666439056, 0.2784672975540161, 0.09207087010145187, -0.09538588672876358, 0.1602480262517929, 0.21629644930362701, -0.03520474210381508, -0.05440386012196541, 0.07467944920063019, 0.3384650647640228, 0.24025429785251617, 0.15470409393310547, -0.08357395231723785, 0.07691057026386261, 0.17796552181243896, -0.04680082947015762, 0.11101385951042175, -0.0026301685720682144, 0.32267647981643677, -0.21150042116641998, -0.09105488657951355, -0.24795466661453247, 0.23636186122894287, 0.09744838625192642, -0.1187196895480156, -0.12922734022140503, 0.1145372986793518, 0.11446305364370346, -0.06431557983160019, 0.33843284845352173, -0.09188837558031082, 0.033617861568927765, -0.12862589955329895, -0.39823561906814575, -0.056771185249090195, 0.14835378527641296, 0.1485150158405304, -0.05140204355120659, 0.42015039920806885, 0.42368659377098083, 0.15137654542922974, 0.1553763896226883, -0.2072252333164215, -0.1430123746395111, -0.07692182064056396, -0.28391170501708984, 0.321492075920105, -0.035636767745018005, -0.10464974492788315, 0.1536385416984558, -0.16514858603477478, 0.09226756542921066, -0.23939085006713867, 0.32200944423675537, -1.7405134898970762e-32, -0.08664361387491226, -0.05248754471540451, -0.06869786977767944, -0.07891145348548889, 0.06745230406522751, -0.19143489003181458, -0.21674951910972595, 0.6144570112228394, -0.3869941830635071, -0.2874090075492859, -0.36675378680229187, 0.19423821568489075, 0.19125127792358398, -0.2556825280189514, 0.1509607881307602, -0.15770196914672852, -0.02295852079987526, -0.37312719225883484, 0.1507939100265503, -0.33744823932647705, -0.1727219969034195, -0.24680471420288086, -0.05671882629394531, -0.12883050739765167, -0.20264792442321777, 0.02353355661034584, 0.22151249647140503, -0.048759881407022476, -0.38792017102241516, 0.029510775581002235, 0.2452581822872162, -0.4059441387653351, -0.15811796486377716, -0.09727899730205536, -0.15320804715156555, -0.30658015608787537, -0.22941729426383972, -0.00769828911870718, 0.18555934727191925, 0.3198292553424835, 0.12509390711784363, 0.19203157722949982, 0.1865188479423523, -0.12624616920948029, 0.25251874327659607, -0.07945236563682556, -0.019907310605049133, -0.2388930320739746, 0.475749135017395, -0.1280047595500946, 0.26875561475753784, -0.08855943381786346, 0.0818461924791336, -0.11439645290374756, 0.1458832323551178, -0.6177549362182617, 0.30291876196861267, 0.16664740443229675, -0.12262223660945892, -0.15794241428375244, -0.28609102964401245, -0.18970201909542084, -0.22973254323005676, -0.15811263024806976, -0.10993748903274536, 0.44800859689712524, 0.08157319575548172, 0.13923248648643494, -0.019504200667142868, -0.21568544209003448, 0.26482081413269043, -0.14027139544487, -0.17531612515449524, -0.14723551273345947, -0.31573358178138733, -0.20246361196041107, -0.1700107604265213, 0.20401903986930847, 0.4875832796096802, -0.03950075805187225, -0.10412485152482986, -0.07889573276042938, 0.1531502604484558, 0.1489405632019043, -0.13021235167980194, -0.23213133215904236, 0.49788665771484375, 0.137051060795784, 0.07042938470840454, 0.39699727296829224, -0.1602535843849182, 0.009064309298992157, 0.02646830305457115, -0.32846811413764954, 0.2509823739528656, -9.946003842742357e-08, -0.24044817686080933, -0.04837555065751076, -0.25824907422065735, 0.45010697841644287, 0.04036889970302582, 0.401577353477478, -0.01270606555044651, 0.27007409930229187, 0.3781135082244873, 0.24277529120445251, -0.03279346227645874, -0.006805079057812691, -0.1534150391817093, 0.21882754564285278, 0.15984667837619781, -0.3093276619911194, 0.17618343234062195, -0.14504998922348022, 0.1985706090927124, -0.15737402439117432, -0.02821236476302147, 0.2080003321170807, 0.07144944369792938, -0.02296736277639866, 0.16735979914665222, -0.4547017812728882, -0.4853765368461609, 0.0095127634704113, 0.1527576446533203, 0.16394761204719543, 0.19515460729599, -0.03762754797935486, -0.24437806010246277, -0.07943826168775558, -0.009060472249984741, -0.32656359672546387, -0.06817224621772766, -0.10637770593166351, 0.4127811789512634, -0.3271113336086273, 0.10111909359693527, -0.21477141976356506, 0.1272539347410202, -0.004939951002597809, -0.2773621082305908, -0.026602458208799362, -0.10095268487930298, -0.012240063399076462, 0.10542020201683044, -0.22113971412181854, 0.0548626184463501, -0.18728795647621155, 0.27076271176338196, -0.19453787803649902, 0.12209416925907135, -0.008776593953371048, -0.10654918849468231, -0.0507492870092392, -0.0636378601193428, 0.2273828089237213, 0.02815192937850952, 0.15591171383857727, -0.15472827851772308, 0.19668275117874146]}, collection='Docs')])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Query the collection to fetch objects, retrieving only the closet \n",
    "# result (limit=1), and include their vector representations in the response\n",
    "collection.query.fetch_objects(limit=1, include_vector=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f37eebd-b108-4936-b3b3-cb6b14ee67d5",
   "metadata": {},
   "source": [
    "# Retrieve Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "581a5bcd-87fb-49fc-a99a-9c97b4051fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the prompt for which you want to find the most relevant document\n",
    "prompt = \"What animals are llamas related to?\"\n",
    "\n",
    "# Generate an embedding for the prompt using the specified model 'all-minilm'\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=\"all-minilm\"\n",
    ")\n",
    "\n",
    "# Query the collection to retrieve the MOST relevant document (limit=1) based on the prompt's embedding\n",
    "results = collection.query.near_vector(near_vector=response[\"embedding\"],\n",
    "                             limit=1)\n",
    "\n",
    "# Extract and display the text of the most relevant document\n",
    "data = results.objects[0].properties['text']\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df904749-538b-49fb-8f1e-d109e3241947",
   "metadata": {},
   "source": [
    "# Augment the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d995b152-aa92-4d06-aff5-bd9f1b4524ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a prompt template that combines the retrieved context (data) \n",
    "# with the original prompt to generate a comprehensive response\n",
    "prompt_template = f\"Using this data: {data}. Respond to this prompt: {prompt}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c9275-47e5-4d79-bbc3-eb38f518fda3",
   "metadata": {},
   "source": [
    "# Generate a Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cc15b5d4-a264-4034-89cd-48f12d8b15a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Llamas are related to several other animals within the camelid family, including:\n",
      "\n",
      "1. Vicuñas: Vicuñas are small, wild cousins of llamas and alpacas. They are native to the Andean region and are known for their soft, luxurious fleece.\n",
      "2. Camels: Llamas are most closely related to camels, with whom they share many physical and behavioral similarities. Both are even-toed ungulates and have adapted to desert environments.\n",
      "3. Guanacos: Guanacos are large, wild cousins of llamas and alpacas. They are native to South America and are known for their distinctive black and white coats.\n",
      "4. Alpacas: Llamas are also related to alpacas, which are domesticated animals commonly kept for their soft fleece. Alpacas are smaller than llamas and have a different coat pattern.\n",
      "\n",
      "Overall, the camelid family is a diverse group of animals that share many similarities in terms of physical characteristics and behavior.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Generate a response from the augmented prompt template\n",
    "output = ollama.generate(\n",
    "  model=\"llama2\",\n",
    "  prompt=prompt_template,\n",
    ")\n",
    "\n",
    "# Print the generated response to the prompt\n",
    "print(output['response'])\n",
    "\n",
    "# Llama2 will answer the prompt \"What animals are llamas related to?\" using the data: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8f524490-5b23-4364-9157-e47e12a3f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the embedded Weaviate instance\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7c4ef-a4fa-4a23-a919-c5a3c2f61006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
