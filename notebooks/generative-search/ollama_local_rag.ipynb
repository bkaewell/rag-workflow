{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd18ae9-2fa8-4f66-a51c-f9ea7b7f7124",
   "metadata": {},
   "source": [
    "\n",
    "# Local Retrieval Augmented Generator (RAG) Pipeline in Python via Ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f66236-8b61-48df-93ef-ea194ba517d0",
   "metadata": {},
   "source": [
    "## Quick Start Guide for Ollama Setup\n",
    "\n",
    "**Ollama** is an open-source Large Language Model (LLM) backend server that streamlines the deployment of LLMs on local environments, utilizing both CPU and GPU resources\n",
    "\n",
    "1. **Download and Install Ollama**  \n",
    "   [Download Ollama]((https://ollama.com/download)) and follow the installation instructions\n",
    "\n",
    "2. **Select Models**  \n",
    "   Browse and choose supported models from the [Ollama library](https://ollama.com/library)\n",
    "\n",
    "3. **Pull the Models**  \n",
    "   Open a terminal and pull the following models:\n",
    "\n",
    "> ```bash\n",
    "> ollama pull llama2      # Language model\n",
    "> ollama pull all-minilm  # Embedding model\n",
    "> ```\n",
    "\n",
    "4. **Install the [Ollama Python library](https://github.com/ollama/ollama-python/blob/main/README.md)**:\n",
    "\n",
    "> ```bash\n",
    "> pip install ollama==0.1.8 # Install Ollama Python library (version 0.1.8)\n",
    "> ```\n",
    "\n",
    "5. **Verify Model Execution**  \n",
    "   Run the model in the terminal to verify it works\n",
    "\n",
    "> ```bash\n",
    "> ollama run llama2\n",
    "> ```\n",
    "\n",
    "6. **Start the Ollama Service for Jupyter Notebook Connection**  \n",
    "   Run the following command in the terminal to start the Ollama service in the background:\n",
    "\n",
    "> ```bash\n",
    "> ollama serve &\n",
    "> ```\n",
    "\n",
    "\n",
    "#### Key Features of Ollama \n",
    "\n",
    "- **Optimized Performance:** Efficiently leverages both CPU and GPU hardware to maximize the speed and performance of supported LLMs\n",
    "- **Flexible Deployment:** Supports easy setup and deployment on local machines, enabling developers full control over model training and inference\n",
    "- **Scalable Architecture:** Designed to handle varying workloads, making it suitable for both small-scale projects and large enterprise applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0109fd3-cb42-4ea1-bb34-0379fd686945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering, which occurs when sunlight travels through the Earth's atmosphere. The sun emits light across the entire electromagnetic spectrum, but the atmosphere scatters the shorter wavelengths (such as blue and violet) more than the longer wavelengths (such as red and orange). This means that when sunlight reaches our eyes, we see mainly the blue and violet light that has been scattered in all directions by the atmosphere.\n",
      "\n",
      "The reason for this scattering is due to the tiny molecules of gases present in the atmosphere, such as nitrogen and oxygen. These molecules are much smaller than the wavelength of visible light, so they don't absorb or reflect the light directly. Instead, they scatter it in all directions, giving the sky its blue appearance.\n",
      "\n",
      "The blue color of the sky can also be affected by other factors such as the presence of aerosols (small particles in the atmosphere) and the angle of the sun. For example, during sunrise and sunset, the sky can take on hues of red, orange, and pink due to the scattering of light by the atmosphere at these angles.\n",
      "\n",
      "In summary, the sky appears blue because of the way sunlight interacts with the Earth's atmosphere, specifically through the scattering of shorter wavelengths (such as blue and violet) by the tiny molecules of gases present in the atmosphere.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the Ollama library to interact with the language models\n",
    "import ollama\n",
    "\n",
    "# Send a chat request to the 'llama2' model with a user message\n",
    "response = ollama.chat(model='llama2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',  # Message content that the user sends to the model\n",
    "  },\n",
    "])\n",
    "\n",
    "# Print the response from the model, displaying the answer to the user's question\n",
    "print(response['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90599b7c-7979-48a4-8416-dbc66f39b591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': [0.0479680672287941,\n",
       "  0.11637094616889954,\n",
       "  -0.24570561945438385,\n",
       "  -0.04406300559639931,\n",
       "  -0.24932530522346497,\n",
       "  0.12218563258647919,\n",
       "  -0.48447176814079285,\n",
       "  -0.1940533071756363,\n",
       "  0.27372273802757263,\n",
       "  0.1956769824028015,\n",
       "  0.26291224360466003,\n",
       "  -0.31583428382873535,\n",
       "  0.28280389308929443,\n",
       "  0.03434046357870102,\n",
       "  0.17188657820224762,\n",
       "  -0.13632719218730927,\n",
       "  0.03992735221982002,\n",
       "  0.13770951330661774,\n",
       "  -0.33948075771331787,\n",
       "  0.3291258215904236,\n",
       "  0.1720881313085556,\n",
       "  0.08957856893539429,\n",
       "  0.33579421043395996,\n",
       "  0.1561996340751648,\n",
       "  -0.11858808994293213,\n",
       "  0.43885111808776855,\n",
       "  -0.11902756989002228,\n",
       "  0.11152736097574234,\n",
       "  -0.012823819182813168,\n",
       "  0.16673514246940613,\n",
       "  -0.34044894576072693,\n",
       "  0.019135579466819763,\n",
       "  -0.110402412712574,\n",
       "  -0.059086285531520844,\n",
       "  -0.3229251801967621,\n",
       "  0.10102441906929016,\n",
       "  0.2166978120803833,\n",
       "  0.74030601978302,\n",
       "  0.3397805392742157,\n",
       "  0.2394002228975296,\n",
       "  0.11844772100448608,\n",
       "  -0.1658744364976883,\n",
       "  0.32743486762046814,\n",
       "  -0.171737402677536,\n",
       "  0.21162186563014984,\n",
       "  -0.20228269696235657,\n",
       "  -0.13644078373908997,\n",
       "  0.3281208872795105,\n",
       "  -0.03160986304283142,\n",
       "  0.333562433719635,\n",
       "  0.020605679601430893,\n",
       "  -0.38323915004730225,\n",
       "  -0.03506068140268326,\n",
       "  -0.16214746236801147,\n",
       "  0.2078971266746521,\n",
       "  -0.22254052758216858,\n",
       "  -0.29925537109375,\n",
       "  -0.032035697251558304,\n",
       "  -0.06888647377490997,\n",
       "  0.08595149219036102,\n",
       "  0.37744516134262085,\n",
       "  0.0854637622833252,\n",
       "  0.0945020318031311,\n",
       "  0.18955892324447632,\n",
       "  0.06756727397441864,\n",
       "  -0.1728506237268448,\n",
       "  -0.0341879241168499,\n",
       "  0.14638245105743408,\n",
       "  0.016109690070152283,\n",
       "  -0.5922088623046875,\n",
       "  -0.1168113499879837,\n",
       "  -0.20937147736549377,\n",
       "  -0.10772979259490967,\n",
       "  0.6877169013023376,\n",
       "  -0.8039499521255493,\n",
       "  0.3414524495601654,\n",
       "  0.518932044506073,\n",
       "  0.17100301384925842,\n",
       "  -0.0356876514852047,\n",
       "  0.22341465950012207,\n",
       "  -0.03832199424505234,\n",
       "  0.4819480776786804,\n",
       "  -0.3232273757457733,\n",
       "  0.24520060420036316,\n",
       "  -0.118628591299057,\n",
       "  0.1250884234905243,\n",
       "  -0.0009830949129536748,\n",
       "  -0.11189250648021698,\n",
       "  -0.03331553190946579,\n",
       "  -0.16391819715499878,\n",
       "  -0.11268705874681473,\n",
       "  -0.4105423092842102,\n",
       "  0.14135390520095825,\n",
       "  0.09108546376228333,\n",
       "  0.15116019546985626,\n",
       "  0.03725185617804527,\n",
       "  0.33115071058273315,\n",
       "  0.07788203656673431,\n",
       "  -0.33126300573349,\n",
       "  -0.07327817380428314,\n",
       "  -0.04304470866918564,\n",
       "  -0.34385788440704346,\n",
       "  0.1361958235502243,\n",
       "  0.16590392589569092,\n",
       "  -0.10033728182315826,\n",
       "  0.08257830142974854,\n",
       "  -0.41402167081832886,\n",
       "  -0.045285243541002274,\n",
       "  -0.07951485365629196,\n",
       "  -0.6535919904708862,\n",
       "  -0.41038447618484497,\n",
       "  0.2744978070259094,\n",
       "  -0.2532588541507721,\n",
       "  0.57249516248703,\n",
       "  -0.006320111453533173,\n",
       "  0.0007175914943218231,\n",
       "  0.06016102060675621,\n",
       "  -0.005822395905852318,\n",
       "  -0.2541661858558655,\n",
       "  -0.46486788988113403,\n",
       "  -0.20756466686725616,\n",
       "  -0.17707332968711853,\n",
       "  0.23001274466514587,\n",
       "  -0.09343764185905457,\n",
       "  0.6981855630874634,\n",
       "  -0.13086853921413422,\n",
       "  -0.24531641602516174,\n",
       "  -2.1621957865684722e-32,\n",
       "  0.311716765165329,\n",
       "  -0.5057485699653625,\n",
       "  0.01705324277281761,\n",
       "  0.11098875850439072,\n",
       "  0.3337019681930542,\n",
       "  -0.11959066241979599,\n",
       "  -0.20247845351696014,\n",
       "  0.5390398502349854,\n",
       "  -0.32604897022247314,\n",
       "  0.17890077829360962,\n",
       "  -0.6165183186531067,\n",
       "  0.19953981041908264,\n",
       "  0.046679094433784485,\n",
       "  0.10165548324584961,\n",
       "  -0.04596211388707161,\n",
       "  0.23492799699306488,\n",
       "  -0.23711749911308289,\n",
       "  -0.4063257575035095,\n",
       "  0.11288788914680481,\n",
       "  -0.7901003360748291,\n",
       "  -0.25783440470695496,\n",
       "  0.6193608641624451,\n",
       "  0.2538302540779114,\n",
       "  -0.1724856197834015,\n",
       "  -0.36256226897239685,\n",
       "  0.1811852753162384,\n",
       "  0.5480149984359741,\n",
       "  -0.5115892887115479,\n",
       "  -0.37637344002723694,\n",
       "  0.20098555088043213,\n",
       "  -0.033785514533519745,\n",
       "  0.021989399567246437,\n",
       "  -0.09501127898693085,\n",
       "  -0.0704611986875534,\n",
       "  -0.34332799911499023,\n",
       "  0.14684535562992096,\n",
       "  -0.31961941719055176,\n",
       "  -0.21937744319438934,\n",
       "  -0.16015826165676117,\n",
       "  -0.026218228042125702,\n",
       "  0.13334238529205322,\n",
       "  0.07665116339921951,\n",
       "  -0.01576843112707138,\n",
       "  0.05724230408668518,\n",
       "  -0.2459472417831421,\n",
       "  -0.012531669810414314,\n",
       "  -0.03919015824794769,\n",
       "  -0.2609476149082184,\n",
       "  0.025538234040141106,\n",
       "  0.2397068589925766,\n",
       "  0.14349175989627838,\n",
       "  0.13313598930835724,\n",
       "  -0.22440055012702942,\n",
       "  0.0375460721552372,\n",
       "  -0.3314935266971588,\n",
       "  -0.10260859876871109,\n",
       "  0.09269706904888153,\n",
       "  0.4185755252838135,\n",
       "  -0.4032041132450104,\n",
       "  0.33022481203079224,\n",
       "  -0.06133243814110756,\n",
       "  -0.17070993781089783,\n",
       "  0.04895436763763428,\n",
       "  0.002864893525838852,\n",
       "  0.15333297848701477,\n",
       "  0.024853672832250595,\n",
       "  -0.161510169506073,\n",
       "  0.1829138845205307,\n",
       "  0.595584511756897,\n",
       "  0.021394841372966766,\n",
       "  0.3477683663368225,\n",
       "  0.42815279960632324,\n",
       "  -0.07422944158315659,\n",
       "  -0.2917013168334961,\n",
       "  0.17846590280532837,\n",
       "  -0.15794479846954346,\n",
       "  0.05370338261127472,\n",
       "  0.1644964963197708,\n",
       "  0.25962382555007935,\n",
       "  0.07016406208276749,\n",
       "  0.14868450164794922,\n",
       "  0.3940960466861725,\n",
       "  0.22665269672870636,\n",
       "  -0.06918759644031525,\n",
       "  -0.4827025532722473,\n",
       "  0.12180975079536438,\n",
       "  0.05855715647339821,\n",
       "  0.19795912504196167,\n",
       "  -0.38132980465888977,\n",
       "  -0.27527397871017456,\n",
       "  0.11255248636007309,\n",
       "  0.32632607221603394,\n",
       "  0.01114906370639801,\n",
       "  -0.29348015785217285,\n",
       "  0.4515606164932251,\n",
       "  3.6550094007338636e-33,\n",
       "  -0.09351867437362671,\n",
       "  -0.1247117891907692,\n",
       "  0.10173609107732773,\n",
       "  -0.10715464502573013,\n",
       "  0.09450113773345947,\n",
       "  -0.24380037188529968,\n",
       "  0.14186657965183258,\n",
       "  0.07952535152435303,\n",
       "  -0.4165605902671814,\n",
       "  0.11948099732398987,\n",
       "  -0.22608107328414917,\n",
       "  -0.043670959770679474,\n",
       "  -0.20230457186698914,\n",
       "  -0.09861423075199127,\n",
       "  0.0683785155415535,\n",
       "  -0.20767831802368164,\n",
       "  -0.1667625606060028,\n",
       "  -0.2523026168346405,\n",
       "  0.02264595590531826,\n",
       "  -0.6602007746696472,\n",
       "  -0.09684134274721146,\n",
       "  0.17300061881542206,\n",
       "  0.15028104186058044,\n",
       "  -0.42491352558135986,\n",
       "  0.04930268973112106,\n",
       "  -0.29075443744659424,\n",
       "  -0.017350755631923676,\n",
       "  0.0779368132352829,\n",
       "  -0.24270233511924744,\n",
       "  0.10396472364664078,\n",
       "  0.06942594051361084,\n",
       "  0.09324230253696442,\n",
       "  -0.0499393604695797,\n",
       "  -0.15659745037555695,\n",
       "  0.07782243192195892,\n",
       "  -0.025172295048832893,\n",
       "  -0.33872929215431213,\n",
       "  0.18270722031593323,\n",
       "  -0.10103240609169006,\n",
       "  -0.2888062596321106,\n",
       "  0.16057203710079193,\n",
       "  0.14942780137062073,\n",
       "  -0.24337708950042725,\n",
       "  -0.08888675272464752,\n",
       "  0.23981910943984985,\n",
       "  0.2925757169723511,\n",
       "  -0.1442246437072754,\n",
       "  -0.16016660630702972,\n",
       "  0.34153643250465393,\n",
       "  -0.04691901430487633,\n",
       "  0.6217111349105835,\n",
       "  -0.15417833626270294,\n",
       "  0.1612258106470108,\n",
       "  -0.01684247888624668,\n",
       "  0.6111409664154053,\n",
       "  -0.07876449078321457,\n",
       "  0.038937151432037354,\n",
       "  -0.1593906730413437,\n",
       "  -0.045119509100914,\n",
       "  -0.03228157386183739,\n",
       "  0.09828085452318192,\n",
       "  -0.16773295402526855,\n",
       "  -0.1177985817193985,\n",
       "  -0.1568637639284134,\n",
       "  0.035316117107868195,\n",
       "  0.045368921011686325,\n",
       "  -0.2880411446094513,\n",
       "  -0.16971388459205627,\n",
       "  0.39351165294647217,\n",
       "  -0.025989454239606857,\n",
       "  0.42037829756736755,\n",
       "  -0.4897196292877197,\n",
       "  -0.3302510976791382,\n",
       "  -0.33643677830696106,\n",
       "  0.24801290035247803,\n",
       "  -0.3171868920326233,\n",
       "  -0.24226275086402893,\n",
       "  -0.2382175773382187,\n",
       "  0.34081411361694336,\n",
       "  -0.07930709421634674,\n",
       "  -0.13654817640781403,\n",
       "  -0.17374423146247864,\n",
       "  0.11038593202829361,\n",
       "  0.3102496266365051,\n",
       "  -0.11108851432800293,\n",
       "  -0.11369770765304565,\n",
       "  0.36472272872924805,\n",
       "  0.4755455255508423,\n",
       "  0.190629780292511,\n",
       "  0.3681891858577728,\n",
       "  -0.019303472712635994,\n",
       "  0.13884013891220093,\n",
       "  0.10116974264383316,\n",
       "  -0.2002669870853424,\n",
       "  0.2967045307159424,\n",
       "  -9.941551581960084e-08,\n",
       "  -0.037738531827926636,\n",
       "  0.015147529542446136,\n",
       "  -0.04523090645670891,\n",
       "  0.3600045442581177,\n",
       "  -0.002262882888317108,\n",
       "  0.5121796727180481,\n",
       "  -0.2656864523887634,\n",
       "  0.5787660479545593,\n",
       "  0.18275569379329681,\n",
       "  0.3565831780433655,\n",
       "  0.37526729702949524,\n",
       "  0.04920816048979759,\n",
       "  -0.0488891638815403,\n",
       "  0.2858676314353943,\n",
       "  0.07148626446723938,\n",
       "  -0.18400438129901886,\n",
       "  0.14617528021335602,\n",
       "  -0.07157988101243973,\n",
       "  -0.048899807035923004,\n",
       "  0.1096830740571022,\n",
       "  -0.3792002201080322,\n",
       "  -0.12634702026844025,\n",
       "  -0.10923678427934647,\n",
       "  -0.03847265988588333,\n",
       "  0.00450064055621624,\n",
       "  -0.48325642943382263,\n",
       "  -0.3404245972633362,\n",
       "  0.14273622632026672,\n",
       "  0.42116302251815796,\n",
       "  0.027788616716861725,\n",
       "  -0.47461867332458496,\n",
       "  -0.320009708404541,\n",
       "  -0.2263825535774231,\n",
       "  -0.3955862522125244,\n",
       "  -0.2089976966381073,\n",
       "  0.1387166678905487,\n",
       "  -0.23458987474441528,\n",
       "  -0.35707882046699524,\n",
       "  0.37242257595062256,\n",
       "  0.03094346821308136,\n",
       "  0.0893300473690033,\n",
       "  -0.6569589376449585,\n",
       "  0.2267596423625946,\n",
       "  0.4163093566894531,\n",
       "  0.2942674160003662,\n",
       "  -0.06821693480014801,\n",
       "  0.280519038438797,\n",
       "  0.04753290116786957,\n",
       "  -0.5188789963722229,\n",
       "  -0.3813299536705017,\n",
       "  0.06510141491889954,\n",
       "  -0.10295283794403076,\n",
       "  0.029293270781636238,\n",
       "  -0.135214164853096,\n",
       "  -0.4602075517177582,\n",
       "  -0.2557786703109741,\n",
       "  -0.2844220995903015,\n",
       "  -0.08383076637983322,\n",
       "  0.3182942271232605,\n",
       "  0.05698961764574051,\n",
       "  0.29283812642097473,\n",
       "  0.06759779155254364,\n",
       "  0.173764169216156,\n",
       "  0.07525268197059631]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Generate vector embeddings for the given text prompt using the specified embedding model 'all-minilm'\n",
    "# Embeddings are used to represent the semantic meaning of the text in a numerical format\n",
    "\n",
    "ollama.embeddings(model=\"all-minilm\", \n",
    "                  prompt=\"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240a206-8282-4518-960a-09a9822a4418",
   "metadata": {},
   "source": [
    "## Quick Start Guide for Weaviate Setup\n",
    "\n",
    "**Weaviate** is an open-source, AI-native vector database designed to store and manage large-scale data. It provides advanced capabilities for AI-driven applications, making it easier to handle data ingestion, querying, and search operations.\n",
    "\n",
    "1. **Install [Python Weaviate library](https://weaviate.io/developers/weaviate/client-libraries/python)**:\n",
    "\n",
    "> ```bash\n",
    "> pip install -U weaviate-client  # Install Weaviate client library (version 4.5.5)\n",
    "> ```\n",
    "\n",
    "#### Key Features of the Weaviate Client Library \n",
    "\n",
    "- **Data Ingestion:** Easily add and manage data within your Weaviate instance \n",
    "- **Querying:** Execute complex queries to retrieve relevant information \n",
    "- **Search Operations:** Perform semantic and vector-based searches for accurate data retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9ec58ce-f434-4ac3-91b0-b8ba8f1eb70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":53686},\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"address\":\"192.168.0.249:53687\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"address\":\"192.168.0.249:53686\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"action\":\"raft\",\"index\":1,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.0.249:59462}]]\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":17,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":17,\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-10-15T16:58:58-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [192.168.0.249:53686]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"192.168.0.249:53686\"],\"time\":\"2024-10-15T16:59:00-04:00\",\"voter\":true}\n",
      "{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"Embedded_at_8079\",\"Address\":\"192.168.0.249:53686\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"bootstrap only works on new clusters\",\"level\":\"error\",\"msg\":\"could not bootstrapping cluster\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"192.168.0.249:53686\"],\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":7,\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":7,\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"index\":\"Docs\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"address\":\"192.168.0.249:53686\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-10-15T16:59:00-04:00\"}\n",
      "{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:6ac6e9a8-1772-4943-b57a-24762ee489a8 Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[]}\",\"time\":\"2024-10-15T16:59:01-04:00\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-10-15T16:59:01-04:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard docs_GpI2uZlxg3Io in 12.138625ms\",\"time\":\"2024-10-15T16:59:01-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-10-15T16:59:01-04:00\",\"took\":645083}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-10-15T16:59:02-04:00\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the Weaviate client library to interact with the Weaviate database\n",
    "import weaviate\n",
    "\n",
    "# Connect to an embedded Weaviate instance, enabling the Python client to interact with the local server at http://127.0.0.1:8079\n",
    "# using HTTP for queries and gRPC (Google Remote Procedure Call) for faster data communication\n",
    "# Start process ID path: /Users/briankaewell/.cache/weaviate-embedded/*\n",
    "client = weaviate.connect_to_embedded()\n",
    "\n",
    "# Check if the Weaviate instance is ready and print the connection status\n",
    "print(client.is_ready())\n",
    "\n",
    "# TO-DO\n",
    "#try:\n",
    "#    pass  # Do something with the client\n",
    "\n",
    "#finally:\n",
    "#    client.close()  # Ensure the connection is closed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c8c00-d18a-4f5d-abe8-e9d67b34d8df",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://weaviate.io/assets/images/rag-ollama-diagram-c71ba5c4e60629e70a2cf334a7716860.png\" alt=\"rag_ollama\" width=\"700\" />\n",
    "  <figcaption>Local Retrieval Augmented Generation (RAG) system with language models via Ollama</figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c25995-21bf-4bbe-b1a7-53965dcbd0e2",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a223777a-fd08-4f8e-a759-4f369cd56c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List contains individual pieces of information (documents) related to llamas, \n",
    "# which may be used for processing or data storage tasks\n",
    "documents = [\n",
    "  \"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\",\n",
    "  \"Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands\",\n",
    "  \"Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall\",\n",
    "  \"Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight\",\n",
    "  \"Llamas are vegetarians and have very efficient digestive systems\",\n",
    "  \"Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794419b-173a-4312-9acb-66ec05e62584",
   "metadata": {},
   "source": [
    "# Create Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a364e598-9220-41fb-9677-1b806334bffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"warning\",\"msg\":\"prop len tracker file /Users/briankaewell/.local/share/weaviate/docs/RPmnTJ9v9FvR/proplengths does not exist, creating new tracker\",\"time\":\"2024-10-15T16:59:53-04:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-10-15T16:59:53-04:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard docs_RPmnTJ9v9FvR in 10.439ms\",\"time\":\"2024-10-15T16:59:53-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-10-15T16:59:53-04:00\",\"took\":128750}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import specific classes from Weaviate to work with data schema and configs for vector database\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.classes.config import Property, DataType\n",
    "\n",
    "# Define the name of the structure (collection)\n",
    "collection_name = \"docs\"\n",
    "\n",
    "# Check if the collection already exists\n",
    "if client.collections.exists(collection_name):\n",
    "    client.collections.delete(collection_name)\n",
    "\n",
    "# Create a new collection with the specified name and define its structure properties\n",
    "collection = client.collections.create(\n",
    "    collection_name,\n",
    "    properties=[\n",
    "        Property(name=\"text\", \n",
    "                 data_type=DataType.TEXT), # Name and data type of a single property for simple list of strings\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f946e4-1439-4d2a-b611-d7665f3a3584",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5e53edb-df8f-4384-a863-0dbe92892faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Store each document in a vector embedding database\n",
    "with collection.batch.dynamic() as batch:\n",
    "  for i, d in enumerate(documents):\n",
    "    # For each document, generate its vector embeddings\n",
    "    response = ollama.embeddings(model=\"all-minilm\", \n",
    "                                 prompt=d)\n",
    "    embedding = response[\"embedding\"]\n",
    "    # Print text and its embedding\n",
    "    # display({f'Document {i}': d, \"Embedding\": embedding}) \n",
    "    \n",
    "    # Store data object with combined text and embedding in the vector embedding database\n",
    "    batch.add_object(\n",
    "        properties = {\"text\" : d},\n",
    "        vector = embedding,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa7071ec-a894-4021-a120-7aae19be8bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('18f07307-25b1-45bd-b601-d5ca4440cd98'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'text': \"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\"}, references=None, vector={'default': [0.0479680672287941, 0.11637094616889954, -0.24570561945438385, -0.04406300559639931, -0.24932530522346497, 0.12218563258647919, -0.48447176814079285, -0.1940533071756363, 0.27372273802757263, 0.1956769824028015, 0.26291224360466003, -0.31583428382873535, 0.28280389308929443, 0.03434046357870102, 0.17188657820224762, -0.13632719218730927, 0.03992735221982002, 0.13770951330661774, -0.33948075771331787, 0.3291258215904236, 0.1720881313085556, 0.08957856893539429, 0.33579421043395996, 0.1561996340751648, -0.11858808994293213, 0.43885111808776855, -0.11902756989002228, 0.11152736097574234, -0.012823819182813168, 0.16673514246940613, -0.34044894576072693, 0.019135579466819763, -0.110402412712574, -0.059086285531520844, -0.3229251801967621, 0.10102441906929016, 0.2166978120803833, 0.74030601978302, 0.3397805392742157, 0.2394002228975296, 0.11844772100448608, -0.1658744364976883, 0.32743486762046814, -0.171737402677536, 0.21162186563014984, -0.20228269696235657, -0.13644078373908997, 0.3281208872795105, -0.03160986304283142, 0.333562433719635, 0.020605679601430893, -0.38323915004730225, -0.03506068140268326, -0.16214746236801147, 0.2078971266746521, -0.22254052758216858, -0.29925537109375, -0.032035697251558304, -0.06888647377490997, 0.08595149219036102, 0.37744516134262085, 0.0854637622833252, 0.0945020318031311, 0.18955892324447632, 0.06756727397441864, -0.1728506237268448, -0.0341879241168499, 0.14638245105743408, 0.016109690070152283, -0.5922088623046875, -0.1168113499879837, -0.20937147736549377, -0.10772979259490967, 0.6877169013023376, -0.8039499521255493, 0.3414524495601654, 0.518932044506073, 0.17100301384925842, -0.0356876514852047, 0.22341465950012207, -0.03832199424505234, 0.4819480776786804, -0.3232273757457733, 0.24520060420036316, -0.118628591299057, 0.1250884234905243, -0.0009830949129536748, -0.11189250648021698, -0.03331553190946579, -0.16391819715499878, -0.11268705874681473, -0.4105423092842102, 0.14135390520095825, 0.09108546376228333, 0.15116019546985626, 0.03725185617804527, 0.33115071058273315, 0.07788203656673431, -0.33126300573349, -0.07327817380428314, -0.04304470866918564, -0.34385788440704346, 0.1361958235502243, 0.16590392589569092, -0.10033728182315826, 0.08257830142974854, -0.41402167081832886, -0.045285243541002274, -0.07951485365629196, -0.6535919904708862, -0.41038447618484497, 0.2744978070259094, -0.2532588541507721, 0.57249516248703, -0.006320111453533173, 0.0007175914943218231, 0.06016102060675621, -0.005822395905852318, -0.2541661858558655, -0.46486788988113403, -0.20756466686725616, -0.17707332968711853, 0.23001274466514587, -0.09343764185905457, 0.6981855630874634, -0.13086853921413422, -0.24531641602516174, -2.1621957865684722e-32, 0.311716765165329, -0.5057485699653625, 0.01705324277281761, 0.11098875850439072, 0.3337019681930542, -0.11959066241979599, -0.20247845351696014, 0.5390398502349854, -0.32604897022247314, 0.17890077829360962, -0.6165183186531067, 0.19953981041908264, 0.046679094433784485, 0.10165548324584961, -0.04596211388707161, 0.23492799699306488, -0.23711749911308289, -0.4063257575035095, 0.11288788914680481, -0.7901003360748291, -0.25783440470695496, 0.6193608641624451, 0.2538302540779114, -0.1724856197834015, -0.36256226897239685, 0.1811852753162384, 0.5480149984359741, -0.5115892887115479, -0.37637344002723694, 0.20098555088043213, -0.033785514533519745, 0.021989399567246437, -0.09501127898693085, -0.0704611986875534, -0.34332799911499023, 0.14684535562992096, -0.31961941719055176, -0.21937744319438934, -0.16015826165676117, -0.026218228042125702, 0.13334238529205322, 0.07665116339921951, -0.01576843112707138, 0.05724230408668518, -0.2459472417831421, -0.012531669810414314, -0.03919015824794769, -0.2609476149082184, 0.025538234040141106, 0.2397068589925766, 0.14349175989627838, 0.13313598930835724, -0.22440055012702942, 0.0375460721552372, -0.3314935266971588, -0.10260859876871109, 0.09269706904888153, 0.4185755252838135, -0.4032041132450104, 0.33022481203079224, -0.06133243814110756, -0.17070993781089783, 0.04895436763763428, 0.002864893525838852, 0.15333297848701477, 0.024853672832250595, -0.161510169506073, 0.1829138845205307, 0.595584511756897, 0.021394841372966766, 0.3477683663368225, 0.42815279960632324, -0.07422944158315659, -0.2917013168334961, 0.17846590280532837, -0.15794479846954346, 0.05370338261127472, 0.1644964963197708, 0.25962382555007935, 0.07016406208276749, 0.14868450164794922, 0.3940960466861725, 0.22665269672870636, -0.06918759644031525, -0.4827025532722473, 0.12180975079536438, 0.05855715647339821, 0.19795912504196167, -0.38132980465888977, -0.27527397871017456, 0.11255248636007309, 0.32632607221603394, 0.01114906370639801, -0.29348015785217285, 0.4515606164932251, 3.6550094007338636e-33, -0.09351867437362671, -0.1247117891907692, 0.10173609107732773, -0.10715464502573013, 0.09450113773345947, -0.24380037188529968, 0.14186657965183258, 0.07952535152435303, -0.4165605902671814, 0.11948099732398987, -0.22608107328414917, -0.043670959770679474, -0.20230457186698914, -0.09861423075199127, 0.0683785155415535, -0.20767831802368164, -0.1667625606060028, -0.2523026168346405, 0.02264595590531826, -0.6602007746696472, -0.09684134274721146, 0.17300061881542206, 0.15028104186058044, -0.42491352558135986, 0.04930268973112106, -0.29075443744659424, -0.017350755631923676, 0.0779368132352829, -0.24270233511924744, 0.10396472364664078, 0.06942594051361084, 0.09324230253696442, -0.0499393604695797, -0.15659745037555695, 0.07782243192195892, -0.025172295048832893, -0.33872929215431213, 0.18270722031593323, -0.10103240609169006, -0.2888062596321106, 0.16057203710079193, 0.14942780137062073, -0.24337708950042725, -0.08888675272464752, 0.23981910943984985, 0.2925757169723511, -0.1442246437072754, -0.16016660630702972, 0.34153643250465393, -0.04691901430487633, 0.6217111349105835, -0.15417833626270294, 0.1612258106470108, -0.01684247888624668, 0.6111409664154053, -0.07876449078321457, 0.038937151432037354, -0.1593906730413437, -0.045119509100914, -0.03228157386183739, 0.09828085452318192, -0.16773295402526855, -0.1177985817193985, -0.1568637639284134, 0.035316117107868195, 0.045368921011686325, -0.2880411446094513, -0.16971388459205627, 0.39351165294647217, -0.025989454239606857, 0.42037829756736755, -0.4897196292877197, -0.3302510976791382, -0.33643677830696106, 0.24801290035247803, -0.3171868920326233, -0.24226275086402893, -0.2382175773382187, 0.34081411361694336, -0.07930709421634674, -0.13654817640781403, -0.17374423146247864, 0.11038593202829361, 0.3102496266365051, -0.11108851432800293, -0.11369770765304565, 0.36472272872924805, 0.4755455255508423, 0.190629780292511, 0.3681891858577728, -0.019303472712635994, 0.13884013891220093, 0.10116974264383316, -0.2002669870853424, 0.2967045307159424, -9.941551581960084e-08, -0.037738531827926636, 0.015147529542446136, -0.04523090645670891, 0.3600045442581177, -0.002262882888317108, 0.5121796727180481, -0.2656864523887634, 0.5787660479545593, 0.18275569379329681, 0.3565831780433655, 0.37526729702949524, 0.04920816048979759, -0.0488891638815403, 0.2858676314353943, 0.07148626446723938, -0.18400438129901886, 0.14617528021335602, -0.07157988101243973, -0.048899807035923004, 0.1096830740571022, -0.3792002201080322, -0.12634702026844025, -0.10923678427934647, -0.03847265988588333, 0.00450064055621624, -0.48325642943382263, -0.3404245972633362, 0.14273622632026672, 0.42116302251815796, 0.027788616716861725, -0.47461867332458496, -0.320009708404541, -0.2263825535774231, -0.3955862522125244, -0.2089976966381073, 0.1387166678905487, -0.23458987474441528, -0.35707882046699524, 0.37242257595062256, 0.03094346821308136, 0.0893300473690033, -0.6569589376449585, 0.2267596423625946, 0.4163093566894531, 0.2942674160003662, -0.06821693480014801, 0.280519038438797, 0.04753290116786957, -0.5188789963722229, -0.3813299536705017, 0.06510141491889954, -0.10295283794403076, 0.029293270781636238, -0.135214164853096, -0.4602075517177582, -0.2557786703109741, -0.2844220995903015, -0.08383076637983322, 0.3182942271232605, 0.05698961764574051, 0.29283812642097473, 0.06759779155254364, 0.173764169216156, 0.07525268197059631]}, collection='Docs')])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Query the collection to fetch objects, retrieving only the closet \n",
    "# result (limit=1), and include their vector representations in the response\n",
    "collection.query.fetch_objects(limit=1, include_vector=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f37eebd-b108-4936-b3b3-cb6b14ee67d5",
   "metadata": {},
   "source": [
    "# Retrieve Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "581a5bcd-87fb-49fc-a99a-9c97b4051fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the prompt for which you want to find the most relevant document\n",
    "prompt = \"What animals are llamas related to?\"\n",
    "\n",
    "# Generate an embedding for the prompt using the specified model 'all-minilm'\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=\"all-minilm\"\n",
    ")\n",
    "\n",
    "# Query the collection to retrieve the MOST relevant document (limit=1) based on the prompt's embedding\n",
    "results = collection.query.near_vector(near_vector=response[\"embedding\"],\n",
    "                             limit=1)\n",
    "\n",
    "# Extract and display the text of the most relevant document\n",
    "data = results.objects[0].properties['text']\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df904749-538b-49fb-8f1e-d109e3241947",
   "metadata": {},
   "source": [
    "# Augment the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d995b152-aa92-4d06-aff5-bd9f1b4524ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a prompt template that combines the retrieved context (data) \n",
    "# with the original prompt to generate a comprehensive response\n",
    "prompt_template = f\"Using this data: {data}. Respond to this prompt: {prompt}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c9275-47e5-4d79-bbc3-eb38f518fda3",
   "metadata": {},
   "source": [
    "# Generate a Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc15b5d4-a264-4034-89cd-48f12d8b15a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Llamas are related to several other animals within the camelid family. Specifically, llamas are most closely related to vicuñas and camels. All three of these animals belong to the Camelidae family and share many similarities in terms of their physical characteristics and behaviors.\n",
      "\n",
      "Vicuñas are the wild ancestors of both llamas and alpacas, and they are found in the Andean regions of South America. Like llamas, vicuñas have a distinctive coat with long guard hairs and a soft undercoat, which makes them well-suited to the cold, dry climate of their native habitat.\n",
      "\n",
      "Camels, on the other hand, are better adapted to the hot, arid environments of North Africa and the Middle East. Despite their differences in terms of size and coat type, all three camelids share a number of key characteristics, including their ability to go without water for long periods of time and their unique digestive system, which allows them to extract moisture from food even when there is little water available.\n",
      "\n",
      "Overall, the close relationship between llamas, vicuñas, and camels reflects the complex evolutionary history of these animals within the Camelidae family. Despite their differences in terms of size, coat type, and habitat, all three species share a common ancestor and have evolved over time to adapt to their respective environments.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Generate a response from the augmented prompt template\n",
    "output = ollama.generate(\n",
    "  model=\"llama2\",\n",
    "  prompt=prompt_template,\n",
    ")\n",
    "\n",
    "# Print the generated response to the prompt\n",
    "print(output['response'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f524490-5b23-4364-9157-e47e12a3f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f18d4-94c6-41e9-b68a-45db4be41b58",
   "metadata": {},
   "source": [
    "**The grep LISTEN filter displays only those ports that are actively listening for incoming connections**\n",
    "\n",
    "> ``` \n",
    "> sudo lsof -i -P -n | grep LISTEN \n",
    "> \n",
    "> ollama    27370   IPv4 0xdfbc846e3834546d      0t0    TCP 127.0.0.1:11434 (LISTEN) \n",
    ">\n",
    "> weaviate- 35147   IPv6 0x53a13eedd360c342      0t0    TCP *:60186 (LISTEN) \n",
    "> weaviate- 35147   IPv6 0x91f60d5cf4124a61      0t0    TCP *:6060 (LISTEN) \n",
    "> weaviate- 35147   IPv4 0x2acb043cb27d74a0      0t0    TCP 192.168.0.249:60188 (LISTEN) \n",
    "> weaviate- 35147   IPv6 0x41d21a8cc4514707      0t0    TCP *:60187 (LISTEN) \n",
    "> weaviate- 35147   IPv4 0xf61841243b061880      0t0    TCP 192.168.0.249:60187 (LISTEN) \n",
    "> weaviate- 35147   IPv6 0x515655760ad88e38      0t0    TCP *:50050 (LISTEN) \n",
    "> weaviate- 35147   IPv4 0x379147eef7c0a3e5      0t0    TCP 127.0.0.1:8079 (LISTEN)\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cad072-2121-4b00-9ccf-ca511ceab6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
